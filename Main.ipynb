{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 274,
   "source": [
    "\n",
    "from numpy.ma.extras import row_stack\n",
    "# import numpy as np\n",
    "from pgmpy.readwrite import BIFReader\n",
    "import random\n",
    "import numpy\n",
    "import copy\n",
    "from collections import deque"
   ],
   "id": "b5bf0225816bf403"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 275,
   "source": [
    "#Parameters\n",
    "GROUP_ID = '04'\n",
    "ALGORITHM = 've'\n",
    "NETWORK_NAME = 'networks/child.bif'\n",
    "REPORT = '[Disease]'\n",
    "EVIDENCE_LEVEL = 'little'\n",
    "EVIDENCE = \"LowerBodyO2=<5; RUQO2=12+; XrayReport=Asy/Patchy\""
   ],
   "id": "940b8be1dafd6b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 276,
   "source": [
    "class Factor:\n",
    "    def __init__(self, variable, variableValues, combos, no_to_name):\n",
    "        self.variables = variable\n",
    "        self.values = variableValues\n",
    "        self.cardinality = []\n",
    "        for combo in combos:\n",
    "            self.cardinality.append(combo)\n",
    "        self.shared = []\n",
    "        self.no_to_name = no_to_name\n",
    "\n",
    "\n",
    "    def addVariables(self, vars):\n",
    "        common_var = []\n",
    "        for i in range(len(vars.variables)):\n",
    "            self.no_to_name.update({vars.variables[i]: vars.no_to_name[vars.variables[i]]})\n",
    "            if vars.variables[i] not in self.variables:\n",
    "                self.variables.append(vars.variables[i])\n",
    "                self.cardinality.append(vars.cardinality[i])\n",
    "            else:\n",
    "                common_var.append(vars.variables[i])\n",
    "                if self.variables.index(vars.variables[i]) not in self.shared:\n",
    "                    self.shared.append(self.variables.index(vars.variables[i]))\n",
    "\n",
    "        return common_var\n",
    "\n",
    "    def cancelOutVariable(self, vars):\n",
    "        for variable in vars:\n",
    "            if variable in self.variables:\n",
    "                self.cardinality.pop(self.variables.index(variable))\n",
    "                self.variables.remove(variable)\n",
    "                self.shared = []\n",
    "            else:\n",
    "                print('Variable not found, issue with sum out function')\n",
    "\n",
    "    def setValues(self, values):\n",
    "        self.values = values\n"
   ],
   "id": "72c7317e20ff1281"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 277,
   "source": [
    "def normalizeDistribution(distribution):\n",
    "    #Normalizes the numbers in a distribution to sum to 1\n",
    "    sum = 0\n",
    "    for value in distribution:\n",
    "        sum += value\n",
    "    if sum != 0:\n",
    "        for i in range(len(distribution)):\n",
    "            distribution[i] = distribution[i] / sum\n",
    "    return distribution\n",
    "\n",
    "def normalizeVEDistribution(distribution):\n",
    "    sum = 0\n",
    "    answer = []\n",
    "    #Normalizes the distribution created in variable elim\n",
    "    for value in distribution:\n",
    "        sum += distribution[value]\n",
    "    if sum != 0:\n",
    "        for value in distribution:\n",
    "            distribution[value] = distribution[value] / sum\n",
    "            answer.append(distribution[value])\n",
    "    return answer"
   ],
   "id": "720e27761c8f323a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 278,
   "source": [
    "def variableElim(query, observedValues, bayesianNetwork):\n",
    "\n",
    "    variableElimination = makeFactors(observedValues, bayesianNetwork)\n",
    "    for variable in reverseOrder(bayesianNetwork):\n",
    "        print(variable)\n",
    "        #variableElimination = makeFactors(variable, observedValues, bayesianNetwork, accessed) + variableElimination\n",
    "        if variable not in observedValues.keys() and variable not in query:\n",
    "            variableElimination = sumOut(variable, variableElimination)\n",
    "    final = pointWise(variableElimination)\n",
    "    return normalizeVEDistribution(final.values)\n",
    "\n",
    "def reverseOrder(network):\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "    order = []\n",
    "    roots = network.get_roots()\n",
    "    for i in roots:\n",
    "        queue.append(i)\n",
    "        visited.add(i)\n",
    "    while queue:\n",
    "        cur = queue.popleft()\n",
    "        order.append(cur)\n",
    "        for i in network.get_children(cur):\n",
    "            if i not in visited:\n",
    "                queue.append(i)\n",
    "                visited.add(i)\n",
    "    order.reverse()\n",
    "    return order\n",
    "\n",
    "\n",
    "def getAllCombinations(factor):\n",
    "\n",
    "    combo = [()]\n",
    "    for num in factor.cardinality:\n",
    "        result = []\n",
    "        translated_result = []\n",
    "        count = 0\n",
    "\n",
    "        for i in range(num):\n",
    "            for nums in combo:\n",
    "                result.append(nums + (i,))\n",
    "                translated_result.append(translateTuple(result[count], factor))\n",
    "                count +=1\n",
    "\n",
    "        translated = translated_result\n",
    "        combo = result\n",
    "\n",
    "\n",
    "    return translated, combo\n",
    "\n",
    "def getEvidenceCombinations(factor, fixed_positions):\n",
    "\n",
    "    def generate_combos(ranges, current_combo, position):\n",
    "        if position == len(ranges):\n",
    "            result.append(tuple(current_combo))\n",
    "            return\n",
    "\n",
    "        for value in ranges[position]:\n",
    "            generate_combos(ranges, current_combo + [value], position + 1)\n",
    "\n",
    "    # Build ranges for each position\n",
    "    ranges = []\n",
    "    for i, card in enumerate(factor.cardinality):\n",
    "        if i in fixed_positions:\n",
    "            ranges.append([fixed_positions[i]])\n",
    "        else:\n",
    "            ranges.append(list(range(card)))\n",
    "\n",
    "    result = []\n",
    "    translated = []\n",
    "    generate_combos(ranges, [], 0)\n",
    "    for combo in result:\n",
    "        translated.append(translateTuple(combo, factor))\n",
    "\n",
    "    return translated, result\n",
    "\n",
    "\n",
    "def translateTuple(tuple, factor):\n",
    "    count = 0\n",
    "    new_tuple = ()\n",
    "    for num in tuple:\n",
    "        variable = factor.variables[count]\n",
    "        new_tuple = new_tuple + (factor.no_to_name[variable][num],)\n",
    "        count+=1\n",
    "\n",
    "    return new_tuple\n",
    "\n",
    "def variablesOppose(opposite, value, shared):\n",
    "    answer = False\n",
    "    new_tuple = value\n",
    "    for i in range(len(opposite)):\n",
    "        if i == shared:\n",
    "            if opposite[i] != value[i]:\n",
    "                first = value[:i]\n",
    "                second = value[i+1:]\n",
    "                new_tuple = first + second\n",
    "                answer = True\n",
    "            else:\n",
    "                answer = False\n",
    "        elif opposite[i] != value[i]:\n",
    "            return False, value\n",
    "    return answer, new_tuple\n",
    "\n",
    "def getValue(possibilities, cpd):\n",
    "\n",
    "    value = cpd.values\n",
    "    for num in possibilities:\n",
    "        '''\n",
    "        ind = cpd.variables.pop(indice)\n",
    "        index = cpd.state_names[ind].index(num)\n",
    "        '''\n",
    "        value = value[num]\n",
    "\n",
    "    return value\n",
    "\n",
    "def shareValues(factor, combined):\n",
    "    for value in factor:\n",
    "        if value not in combined:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def makeFactors(evidence, network):\n",
    "    factors = []\n",
    "    for factor in network.cpds:\n",
    "        if factor.variables[0] not in evidence.keys():\n",
    "            values = {}\n",
    "            num = 0\n",
    "            combos, nums = getAllCombinations(factor)\n",
    "            for combo in combos:\n",
    "                probability = getValue(nums[num], factor)\n",
    "                values.update({combo:probability})\n",
    "                num+=1\n",
    "            factors.append(Factor(factor.variables, values, factor.cardinality, factor.no_to_name))\n",
    "        else:\n",
    "            values = {}\n",
    "            num = 0\n",
    "            copied = copy.deepcopy(factor)\n",
    "            for key in evidence:\n",
    "                if key in factor.variables:\n",
    "                    ev = key\n",
    "                    ev_index = factor.variables.index(key)\n",
    "                    value_index = factor.state_names[key].index(evidence[key])\n",
    "                    break\n",
    "\n",
    "\n",
    "            evidence_factor = Factor(factor.variables, values, factor.cardinality, factor.no_to_name)\n",
    "            evidence_factor.cardinality[ev_index] = 1\n",
    "            new_mapping = {ev:{value_index:evidence[ev]}}\n",
    "            evidence_factor.no_to_name.pop(ev)\n",
    "            evidence_factor.no_to_name.update(new_mapping)\n",
    "\n",
    "            combos,nums = getEvidenceCombinations(evidence_factor, {ev_index:value_index})\n",
    "            for combo in combos:\n",
    "                probability = getValue(nums[num], copied)\n",
    "                values.update({combo:probability})\n",
    "                num+=1\n",
    "            factors.append(Factor(factor.variables, values, evidence_factor.cardinality, evidence_factor.no_to_name))\n",
    "    return factors\n",
    "\n",
    "\n",
    "def sumOut(variable, variableElimination):\n",
    "    factors_with = []\n",
    "    factors_without = []\n",
    "    for factor in variableElimination:\n",
    "        if variable not in factor.variables:\n",
    "            factors_without.append(factor)\n",
    "        else:\n",
    "            factors_with.append(factor)\n",
    "    combine = pointWise(factors_with)\n",
    "    new_values = {}\n",
    "    removed = []\n",
    "    for value in combine.values:\n",
    "\n",
    "        if value not in removed:\n",
    "            sum = combine.values[value]\n",
    "            new_tuple = value\n",
    "            for opposite in combine.values:\n",
    "                index = combine.variables.index(variable)\n",
    "                oppose, tuple = variablesOppose(opposite, value, index)\n",
    "                if oppose:\n",
    "                    sum += combine.values[opposite]\n",
    "                    removed.append(opposite)\n",
    "                    new_tuple = tuple\n",
    "            new_values.update({new_tuple:sum})\n",
    "\n",
    "    combine.setValues(new_values)\n",
    "    combine.cancelOutVariable([variable])\n",
    "    comb = combine.values.values()\n",
    "    for value in comb:\n",
    "        if not value + 0.000001 >= 1.0:\n",
    "            factors_without.append(combine)\n",
    "            break\n",
    "    return factors_without\n",
    "\n",
    "\n",
    "def pointWise(variableElimination):\n",
    "\n",
    "    temp_factor = copy.deepcopy(variableElimination[0]) #make a copy so we don't overwrite the Factor object\n",
    "\n",
    "    for n in range(len(variableElimination) - 1): #iterate through all other factors\n",
    "        previous_temp = copy.deepcopy(temp_factor)\n",
    "\n",
    "        temp_factor.addVariables(variableElimination[n+1]) #adds new variables and finds the index of the shared variables\n",
    "\n",
    "        temp_values = {}    #dictionary will hold combined values and its probability\n",
    "        for combo, prob1 in previous_temp.values.items(): #get all key value pairs from combined dictionary before adding new variables\n",
    "            for key2, prob2 in variableElimination[n+1].values.items(): #get all key value pairs of new factor\n",
    "                compatible = True\n",
    "                for var in variableElimination[n+1].variables:  #for each variable in new factor\n",
    "                    for value in temp_factor.shared:            #for every shared variable\n",
    "                        if var == previous_temp.variables[value]:   #if they match the variable in the previously combined variables\n",
    "                            idx1 = previous_temp.variables.index(var) #index of matched variable in combo\n",
    "                            idx2 = variableElimination[n+1].variables.index(var) #index of matched variable in new factor\n",
    "                            if combo[idx1] != key2[idx2]:       #if matched variables value are not the same\n",
    "                                compatible = False\n",
    "                                break\n",
    "                if compatible:\n",
    "                    combined = []\n",
    "                    for var in temp_factor.variables:       #every factor in combined variables\n",
    "                        if var in previous_temp.variables:  #if variable already part of the last combined variables\n",
    "                            combined.append(combo[previous_temp.variables.index(var)])  #append the old variables\n",
    "                        else:\n",
    "                            combined.append(key2[variableElimination[n+1].variables.index(var)]) #append the new variables\n",
    "\n",
    "                    temp_values[tuple(combined)] = prob1 * prob2    #get the product\n",
    "\n",
    "        temp_factor.setValues(temp_values)  #set the new probabilities\n",
    "\n",
    "    return temp_factor\n"
   ],
   "id": "b14993bf36bd2a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 279,
   "source": [
    "def gibbsSampling(Network, reportedVars, evidenceVars, numSamples, burnInLength):\n",
    "    possVals = Network.states\n",
    "    randomVals = {}\n",
    "\n",
    "    #Initializing random state values\n",
    "    for key in possVals.keys():\n",
    "        if key in evidenceVars.keys():\n",
    "            randomVals[key] = evidenceVars[key]\n",
    "        else:\n",
    "            randomVals[key] = random.choice(possVals[key])\n",
    "\n",
    "    #initializing counting tables\n",
    "    countingTables = []\n",
    "    for var in reportedVars:\n",
    "        countingTable = []\n",
    "        for i in range(len(possVals[var])):\n",
    "            #case where one of the reported vars is given as evidence\n",
    "            if(var in evidenceVariables):\n",
    "                countingTable.append('x')\n",
    "            else:\n",
    "                countingTable.append(0)\n",
    "        countingTables.append(countingTable)\n",
    "\n",
    "    for i in range(numSamples):\n",
    "        #Need to pick a random (non evidence) node use its markov blanket\n",
    "        randVar = random.choice(list(Network.nodes))\n",
    "        while(randVar in evidenceVars.keys()):\n",
    "            randVar = random.choice(list(Network.nodes))\n",
    "        mb = getParentsAndChildren(Network, randVar)\n",
    "        #Calculate probability of variable given its parents\n",
    "        cpds = Network.get_cpds(randVar)\n",
    "        valueDistribution = []\n",
    "        for value in cpds.state_names[randVar]:\n",
    "            #Calculates P(x_i|parents(X_i))\n",
    "            parents = mb[0]\n",
    "            valueArrIndex = cpds.name_to_no[randVar][value]\n",
    "            valueArr = cpds.values[valueArrIndex]\n",
    "            for parent in parents:\n",
    "                parentVal = randomVals[parent]\n",
    "                parentArrIndex = cpds.name_to_no[parent][parentVal]\n",
    "                valueArr = valueArr[parentArrIndex]\n",
    "            varVal = valueArr\n",
    "            childrenProb = 1\n",
    "            #Calculates/sums all child probabilities P(y_j | parents(y_j))\n",
    "            for children in mb[1]:\n",
    "                childCpds = Network.get_cpds(children)\n",
    "                parents = Network.get_parents(children)\n",
    "                childrenArrIndex = childCpds.name_to_no[children][randomVals[children]]\n",
    "                childrenArr = childCpds.values[childrenArrIndex]\n",
    "                for parent in parents:\n",
    "                    if(parent != randVar):\n",
    "                        parentVal = randomVals[parent]\n",
    "                    else:\n",
    "                        parentVal = value\n",
    "                    parentArrIndex = childCpds.name_to_no[parent][parentVal]\n",
    "                    childrenArr = childrenArr[parentArrIndex]\n",
    "                #Fix for 0 probabilities causing the sampling to get stuck in a state\n",
    "                if(childrenArr == 0):\n",
    "                    childrenArr = 0.05\n",
    "                childrenProb *= childrenArr\n",
    "            valueDistribution.append(varVal*childrenProb)\n",
    "        #normalized value distribution for randomly selected variable has been found\n",
    "        valueDistribution = normalizeDistribution(valueDistribution)\n",
    "        possibleVals = Network.states[randVar]\n",
    "        chosenVal = numpy.random.choice(possibleVals, p = valueDistribution)\n",
    "        #setting the variable's randomly (probability-distribution) based value\n",
    "        randomVals[randVar] = chosenVal\n",
    "        #counting value for reported variable if not in burn in period\n",
    "        if(i >= burnInLength):\n",
    "            for t in range(len(countingTables)):\n",
    "                countingIndex = possVals[reportedVars[t]].index(randomVals[reportedVars[t]])\n",
    "                #check for case where reported variable is also a part of evidence\n",
    "                if(countingTables[t][0] != 'x'):\n",
    "                    countingTables[t][countingIndex] += 1\n",
    "\n",
    "\n",
    "    for table in countingTables:\n",
    "        if(table[0] != 'x'):\n",
    "            table = normalizeDistribution(table)\n",
    "    return countingTables\n",
    "\n",
    "\n",
    "def getParentsAndChildren(Network, variable):\n",
    "    #Gets a sorted list of parents and children variables of a random variable\n",
    "    #Used for easier access of a variable's markov blanket\n",
    "    mb = Network.get_markov_blanket(variable)\n",
    "    nodes = []\n",
    "    parents = Network.get_parents(variable)\n",
    "    children = []\n",
    "    for node in mb:\n",
    "        nodeParents = Network.get_parents(node)\n",
    "        if variable in nodeParents:\n",
    "            children.append(node)\n",
    "    nodes.append(parents)\n",
    "    nodes.append(children)\n",
    "    return nodes"
   ],
   "id": "77dc9735471b2360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GruntingReport\n",
      "XrayReport\n",
      "CO2Report\n",
      "RUQO2\n",
      "LowerBodyO2\n",
      "Grunting\n",
      "ChestXray\n",
      "CO2\n",
      "HypoxiaInO2\n",
      "HypDistrib\n",
      "LVHreport\n",
      "Sick\n",
      "LungFlow\n",
      "LungParench\n",
      "CardiacMixing\n",
      "DuctFlow\n",
      "LVH\n",
      "Age\n",
      "Disease\n",
      "BirthAsphyxia\n",
      "0.13\n",
      "0.22\n",
      "0.23\n",
      "0.18\n",
      "0.06\n",
      "0.18\n"
     ]
    }
   ],
   "execution_count": 280,
   "source": [
    "def createOutput(reportVariables, network, probabilityDistribution):\n",
    "    #writes the file output for gibbs sampling to a text file\n",
    "    fileName = GROUP_ID + '_' + ALGORITHM + '_' + NETWORK_NAME.lstrip('networks/').rstrip('.bif') + '_' + EVIDENCE_LEVEL + '.csv'\n",
    "    states = network.states\n",
    "    with(open(fileName, 'w') as file):\n",
    "        counter = -1\n",
    "        for var in reportVariables:\n",
    "            file.write(var)\n",
    "            counter += 1\n",
    "            for state in states[var]:\n",
    "                file.write(\",\")\n",
    "                file.write(state)\n",
    "            file.write(\"\\n\")\n",
    "            if ALGORITHM == \"gibbs\":\n",
    "                for i in range(len(probabilityDistribution[counter])):\n",
    "                    file.write(str(probabilityDistribution[counter][i]))\n",
    "                    if i != len(probabilityDistribution[counter])-1:\n",
    "                        file.write(\",\")\n",
    "                    else:\n",
    "                        file.write(\"\\n\")\n",
    "            else:\n",
    "                file.write(str(probabilityDistribution[counter]))\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "def createVEOutput(network, probabilityDistribution,var):\n",
    "    #writes the file output for gibbs sampling to a text file\n",
    "    fileName = GROUP_ID + '_' + ALGORITHM + '_' + NETWORK_NAME.lstrip('networks/').rstrip('.bif') + '_' + EVIDENCE_LEVEL + '.csv'\n",
    "    states = network.states\n",
    "    with(open(fileName, 'a') as file):\n",
    "        file.write(var)\n",
    "        for state in states[var]:\n",
    "            file.write(\",\")\n",
    "            file.write(state)\n",
    "        file.write(\"\\n\")\n",
    "        if ALGORITHM == \"ve\":\n",
    "            for i, n in enumerate(probabilityDistribution):\n",
    "                file.write(str(round(n, 2)))\n",
    "                print(str(round(n, 2)))\n",
    "                if i < len(probabilityDistribution) - 1:\n",
    "                    file.write(\",\")\n",
    "                else:\n",
    "                    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "#function for sanitizing input\n",
    "def removeSpace(string):\n",
    "    newStr = ''\n",
    "    for c in string:\n",
    "        if c != ' ':\n",
    "            newStr += c\n",
    "    return newStr\n",
    "\n",
    "\n",
    "\n",
    "reader = BIFReader(NETWORK_NAME)\n",
    "model = reader.get_model()\n",
    "reportList = REPORT.lstrip('[').rstrip(']')\n",
    "reportVariables1 = reportList.split(',')\n",
    "reportVariables = []\n",
    "for var in reportVariables1:\n",
    "    reportVariables.append(removeSpace(var))\n",
    "evidenceVariables = {}\n",
    "if(EVIDENCE_LEVEL != \"None\"):\n",
    "    splitter = EVIDENCE.split(\";\")\n",
    "    for var in splitter:\n",
    "        #Edge case for variables with '=' characters in their values\n",
    "        if'\"' in var:\n",
    "            splitter2 = var.split('\"')\n",
    "            evidenceVariables[splitter2[0][:-1].strip()] = splitter2[1].strip()\n",
    "        else:\n",
    "            splitter2 = var.split(\"=\")\n",
    "            evidenceVariables[splitter2[0].strip()] = splitter2[1].strip()\n",
    "\n",
    "\n",
    "#runs the algorithm corresponding to the input\n",
    "if ALGORITHM == \"gibbs\":\n",
    "    probDist = gibbsSampling(model,reportVariables,evidenceVariables, 210000, 10000)\n",
    "    createOutput(reportVariables, model, probDist)\n",
    "elif ALGORITHM == \"ve\":\n",
    "    for variable in reportVariables:\n",
    "        probDist = variableElim(variable, evidenceVariables, model)\n",
    "        createVEOutput(model,probDist,variable)\n",
    "\n",
    "else:\n",
    "    print(\"Unrecognized algorithm:\", ALGORITHM)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ba38bd0d259f7b13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
