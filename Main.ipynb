{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:46:46.370908Z",
     "start_time": "2025-11-03T18:46:40.602529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from numpy.ma.extras import row_stack\n",
    "# import numpy as np\n",
    "from pgmpy.readwrite import BIFReader\n",
    "import random\n",
    "import numpy\n",
    "import copy"
   ],
   "id": "d295d23e0c305760",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Natha\\Desktop\\CompSci\\Fall 2025\\CSCI 466\\AI_Project3\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:46:46.382861Z",
     "start_time": "2025-11-03T18:46:46.379132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Parameters\n",
    "GROUP_ID = '04'\n",
    "ALGORITHM = 've'\n",
    "NETWORK_NAME = 'networks/child.bif'\n",
    "REPORT = '[Disease]'\n",
    "EVIDENCE_LEVEL = 'None'\n",
    "EVIDENCE = 'Problem5 =Yes'"
   ],
   "id": "c8e189043230b69b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:46:46.400352Z",
     "start_time": "2025-11-03T18:46:46.393436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Factor:\n",
    "    def __init__(self, variable, variableValues, combos, no_to_name):\n",
    "        self.variables = variable\n",
    "        self.values = variableValues\n",
    "        self.cardinality = []\n",
    "        for combo in combos:\n",
    "            self.cardinality.append(combo)\n",
    "        self.shared = []\n",
    "        self.no_to_name = no_to_name\n",
    "\n",
    "\n",
    "    def addVariables(self, vars):\n",
    "        common_var = []\n",
    "        for i in range(len(vars.variables)):\n",
    "            self.no_to_name.update({vars.variables[i]: vars.no_to_name[vars.variables[i]]})\n",
    "            if vars.variables[i] not in self.variables:\n",
    "                self.variables.append(vars.variables[i])\n",
    "                self.cardinality.append(vars.cardinality[i])\n",
    "            else:\n",
    "                common_var.append(vars.variables[i])\n",
    "                if self.variables.index(vars.variables[i]) not in self.shared:\n",
    "                    self.shared.append(self.variables.index(vars.variables[i]))\n",
    "\n",
    "        return common_var\n",
    "\n",
    "    def cancelOutVariable(self, vars):\n",
    "        for variable in vars:\n",
    "            if variable in self.variables:\n",
    "                self.cardinality.pop(self.variables.index(variable))\n",
    "                self.variables.remove(variable)\n",
    "                self.shared = []\n",
    "            else:\n",
    "                print('Variable not found, issue with sum out function')\n",
    "\n",
    "    def setValues(self, values):\n",
    "        self.values = values\n"
   ],
   "id": "a59e608029f3f26",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:46:46.413994Z",
     "start_time": "2025-11-03T18:46:46.409360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalizeDistribution(distribution):\n",
    "    sum = 0\n",
    "    #ogDist = copy.deepcopy(distribution)\n",
    "    for value in distribution:\n",
    "        sum += value\n",
    "    if sum != 0:\n",
    "        for i in range(len(distribution)):\n",
    "            distribution[i] = distribution[i] / sum\n",
    "    return distribution\n",
    "\n",
    "def normalizeVEDistribution(distribution):\n",
    "    sum = 0\n",
    "    #ogDist = copy.deepcopy(distribution)\n",
    "    for value in distribution:\n",
    "        sum += distribution[value]\n",
    "    if sum != 0:\n",
    "        for value in distribution:\n",
    "            distribution[value] = distribution[value] / sum\n",
    "    return distribution"
   ],
   "id": "d88e769e07ccd65d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:46:52.407568Z",
     "start_time": "2025-11-03T18:46:52.322656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def variableElim(query, observedValues, bayesianNetwork):\n",
    "    variableElimination = []\n",
    "    for variable in Order(bayesianNetwork, query):\n",
    "        variableElimination = makeFactors(variable, observedValues, bayesianNetwork) + variableElimination\n",
    "        if variable not in observedValues.keys() and variable not in query:\n",
    "            variableElimination = sumOut(variable, variableElimination)\n",
    "    final = pointWise(variableElimination)\n",
    "    return normalizeVEDistribution(final.values)\n",
    "\n",
    "def Order(variables, query):\n",
    "    order = []\n",
    "    queries = []\n",
    "    for variable in variables:\n",
    "        inside = variables.in_degree[variable]\n",
    "        out = variables.out_degree[variable]\n",
    "        if variable not in query:\n",
    "            if order != []:\n",
    "                if out >= variables.out_degree[order[0]]:\n",
    "                    order.insert(0, variable)\n",
    "                elif out <= variables.out_degree[order[len(order)-1]]:\n",
    "                    order.append(variable)\n",
    "                else:\n",
    "                    for i in range(len(order)):\n",
    "                        if out == variables.out_degree[order[i]]:\n",
    "                            order.insert(i, variable)\n",
    "                            break\n",
    "            else:\n",
    "                order.append(variable)\n",
    "        else:\n",
    "            queries.append(variable)\n",
    "\n",
    "\n",
    "    order = order + queries\n",
    "    return order\n",
    "\n",
    "def getAllCombinations(factor):\n",
    "\n",
    "    combo = [()]\n",
    "    for num in factor.cardinality:\n",
    "        result = []\n",
    "        translated_result = []\n",
    "        count = 0\n",
    "\n",
    "        for i in range(num):\n",
    "            for nums in combo:\n",
    "                result.append(nums + (i,))\n",
    "                translated_result.append(translateTuple(result[count], factor))\n",
    "                count +=1\n",
    "\n",
    "        translated = translated_result\n",
    "        combo = result\n",
    "\n",
    "\n",
    "    return translated, combo\n",
    "\n",
    "def translateTuple(tuple, factor):\n",
    "    count = 0\n",
    "    new_tuple = ()\n",
    "    for num in tuple:\n",
    "        variable = factor.variables[count]\n",
    "        new_tuple = new_tuple + (factor.no_to_name[variable][num],)\n",
    "        count+=1\n",
    "\n",
    "    return new_tuple\n",
    "\n",
    "def variablesOppose(opposite, value, shared):\n",
    "    answer = False\n",
    "    new_tuple = value\n",
    "    for i in range(len(opposite)):\n",
    "        if i == shared:\n",
    "            if opposite[i] != value[i]:\n",
    "                first = value[:i]\n",
    "                second = value[i+1:]\n",
    "                new_tuple = first + second\n",
    "                answer = True\n",
    "            else:\n",
    "                answer = False\n",
    "        elif opposite[i] != value[i]:\n",
    "            return False, value\n",
    "    return answer, new_tuple\n",
    "\n",
    "def getValue(possibilities, cpd):\n",
    "\n",
    "    value = cpd.values\n",
    "    for num in possibilities:\n",
    "        '''\n",
    "        ind = cpd.variables.pop(indice)\n",
    "        index = cpd.state_names[ind].index(num)\n",
    "        '''\n",
    "        value = value[num]\n",
    "\n",
    "    return value\n",
    "\n",
    "def shareValues(factor, combined):\n",
    "    for value in factor:\n",
    "        if value not in combined:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def makeFactors(variable, evidence, network):\n",
    "    factors = []\n",
    "    for factor in network.cpds:\n",
    "        if variable == factor.variables[0]:\n",
    "            values = {}\n",
    "            num = 0\n",
    "            combos, nums = getAllCombinations(factor)\n",
    "            for combo in combos:\n",
    "                probability = getValue(nums[num], factor)\n",
    "                values.update({combo:probability})\n",
    "                num+=1\n",
    "            factors.append(Factor(factor.variables, values, factor.cardinality, factor.no_to_name))\n",
    "    return factors\n",
    "\n",
    "\n",
    "def sumOut(variable, variableElimination):\n",
    "    factors_with = []\n",
    "    factors_without = []\n",
    "    for factor in variableElimination:\n",
    "        if variable not in factor.variables:\n",
    "            factors_without.append(factor)\n",
    "        else:\n",
    "            factors_with.append(factor)\n",
    "    '''\n",
    "    if len(factors_with) == 1:\n",
    "        factors_without.append(factors_with[0])\n",
    "        return factors_without\n",
    "    '''\n",
    "    combine = pointWise(factors_with)\n",
    "    new_values = {}\n",
    "    removed = []\n",
    "    for value in combine.values:\n",
    "\n",
    "        if value not in removed:\n",
    "            sum = combine.values[value]\n",
    "            new_tuple = value\n",
    "            for opposite in combine.values:\n",
    "                index = combine.variables.index(variable)\n",
    "                oppose, tuple = variablesOppose(opposite, value, index)\n",
    "                if oppose:\n",
    "                    sum += combine.values[opposite]\n",
    "                    removed.append(opposite)\n",
    "                    new_tuple = tuple\n",
    "            new_values.update({new_tuple:sum})\n",
    "\n",
    "    combine.setValues(new_values)\n",
    "    combine.cancelOutVariable([variable])\n",
    "    comb = combine.values.values()\n",
    "    for value in comb:\n",
    "        if not value + 0.000001 >= 1.0:\n",
    "            factors_without.append(combine)\n",
    "            break\n",
    "    return factors_without\n",
    "\n",
    "def pointWise(variableElimination):\n",
    "\n",
    "    temp_factor = copy.deepcopy(variableElimination[0])\n",
    "\n",
    "    for n in range(len(variableElimination) - 1):\n",
    "        shared_vars = temp_factor.addVariables(variableElimination[n+1])\n",
    "\n",
    "        combos, nums = getAllCombinations(temp_factor)\n",
    "\n",
    "        temp_values = {}\n",
    "\n",
    "        for combo in combos:\n",
    "            for value in variableElimination[n+1].values:\n",
    "                if shareValues(value, combo):\n",
    "                    first = variableElimination[n+1].values[value]\n",
    "                    break\n",
    "            for value in temp_factor.values:\n",
    "                if shareValues(value, combo):\n",
    "                    second = temp_factor.values[value]\n",
    "                    break\n",
    "            product = first * second\n",
    "            temp_values.update({combo:product})\n",
    "\n",
    "        temp_factor.setValues(temp_values)\n",
    "\n",
    "    return temp_factor\n",
    "\n",
    "def gibbsSampling(Network, reportedVars, evidenceVars, numSamples, burnInLength):\n",
    "    possVals = Network.states\n",
    "    randomVals = {}\n",
    "\n",
    "    #Initializing random state values\n",
    "    for key in possVals.keys():\n",
    "        if key in evidenceVars.keys():\n",
    "            randomVals[key] = evidenceVars[key]\n",
    "        else:\n",
    "            randomVals[key] = random.choice(possVals[key])\n",
    "\n",
    "    #initializing counting tables\n",
    "    countingTables = []\n",
    "    for var in reportedVars:\n",
    "        countingTable = []\n",
    "        for i in range(len(possVals[var])):\n",
    "            #case where one of the reported vars is given as evidence\n",
    "            if(var in evidenceVariables):\n",
    "                countingTable.append('x')\n",
    "            else:\n",
    "                countingTable.append(0)\n",
    "        countingTables.append(countingTable)\n",
    "\n",
    "    for i in range(numSamples):\n",
    "        #Need to pick a random (non evidence) node use its markov blanket\n",
    "        randVar = random.choice(list(Network.nodes))\n",
    "        while(randVar in evidenceVars.keys()):\n",
    "            randVar = random.choice(list(Network.nodes))\n",
    "        mb = getParentsAndChildren(Network, randVar)\n",
    "        #Calculate probability of variable given its parents\n",
    "        cpds = Network.get_cpds(randVar)\n",
    "        valueDistribution = []\n",
    "        for value in cpds.state_names[randVar]:\n",
    "            #Calculates P(x_i|parents(X_i))\n",
    "            parents = mb[0]\n",
    "            valueArrIndex = cpds.name_to_no[randVar][value]\n",
    "            valueArr = cpds.values[valueArrIndex]\n",
    "            for parent in parents:\n",
    "                parentVal = randomVals[parent]\n",
    "                parentArrIndex = cpds.name_to_no[parent][parentVal]\n",
    "                valueArr = valueArr[parentArrIndex]\n",
    "            varVal = valueArr\n",
    "            childrenProb = 1\n",
    "            #Calculates/sums all child probabilities P(y_j | parents(y_j))\n",
    "            for children in mb[1]:\n",
    "                childCpds = Network.get_cpds(children)\n",
    "                parents = Network.get_parents(children)\n",
    "                childrenArrIndex = childCpds.name_to_no[children][randomVals[children]]\n",
    "                childrenArr = childCpds.values[childrenArrIndex]\n",
    "                for parent in parents:\n",
    "                    if(parent != randVar):\n",
    "                        parentVal = randomVals[parent]\n",
    "                    else:\n",
    "                        parentVal = value\n",
    "                    parentArrIndex = childCpds.name_to_no[parent][parentVal]\n",
    "                    childrenArr = childrenArr[parentArrIndex]\n",
    "                #Fix for 0 probabilities causing the sampling to get stuck\n",
    "                if(childrenArr == 0):\n",
    "                    childrenArr = 0.05\n",
    "                childrenProb *= childrenArr\n",
    "            valueDistribution.append(varVal*childrenProb)\n",
    "        #normalized value distribution for randomly selected variable has been found\n",
    "        valueDistribution = normalizeDistribution(valueDistribution)\n",
    "        possibleVals = Network.states[randVar]\n",
    "        chosenVal = numpy.random.choice(possibleVals, p = valueDistribution)\n",
    "        #setting the variable's randomly (probability-distribution) based value\n",
    "        randomVals[randVar] = chosenVal\n",
    "        #counting value for reported variable if not in burn in period\n",
    "        if(i >= burnInLength):\n",
    "            for t in range(len(countingTables)):\n",
    "                countingIndex = possVals[reportedVars[t]].index(randomVals[reportedVars[t]])\n",
    "                #check for case where reported variable is also a part of evidence\n",
    "                if(countingTables[t][0] != 'x'):\n",
    "                    countingTables[t][countingIndex] += 1\n",
    "\n",
    "\n",
    "    for table in countingTables:\n",
    "        if(table[0] != 'x'):\n",
    "            table = normalizeDistribution(table)\n",
    "    print(countingTables)\n",
    "    return countingTables\n",
    "\n",
    "\n",
    "def getParentsAndChildren(Network, variable):\n",
    "    mb = Network.get_markov_blanket(variable)\n",
    "    nodes = []\n",
    "    parents = Network.get_parents(variable)\n",
    "    children = []\n",
    "    for node in mb:\n",
    "        nodeParents = Network.get_parents(node)\n",
    "        if variable in nodeParents:\n",
    "            children.append(node)\n",
    "    nodes.append(parents)\n",
    "    nodes.append(children)\n",
    "    return nodes"
   ],
   "id": "6956ad6e89802371",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T18:47:39.769828Z",
     "start_time": "2025-11-03T18:46:57.053745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def createOutput(reportVariables, network, probabilityDistribution):\n",
    "    fileName = GROUP_ID + '_' + ALGORITHM + '_' + NETWORK_NAME.lstrip('networks/').rstrip('.bif') + '_' + EVIDENCE_LEVEL + '.csv'\n",
    "    states = network.states\n",
    "    with(open(fileName, 'w') as file):\n",
    "        counter = -1\n",
    "        for var in reportVariables:\n",
    "            file.write(var)\n",
    "            counter += 1\n",
    "            for state in states[var]:\n",
    "                file.write(\",\")\n",
    "                file.write(state)\n",
    "            file.write(\"\\n\")\n",
    "            for i in range(len(probabilityDistribution[counter])):\n",
    "                file.write(str(probabilityDistribution[counter][i]))\n",
    "                if i != len(probabilityDistribution[counter])-1:\n",
    "                    file.write(\",\")\n",
    "                else:\n",
    "                    file.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reader = BIFReader(NETWORK_NAME)\n",
    "model = reader.get_model()\n",
    "reportList = REPORT.lstrip('[').rstrip(']')\n",
    "reportVariables = reportList.split(',')\n",
    "for var in reportVariables:\n",
    "    var = var.strip()\n",
    "evidenceVariables = {}\n",
    "if(EVIDENCE_LEVEL != \"None\"):\n",
    "    splitter = EVIDENCE.split(\";\")\n",
    "    for var in splitter:\n",
    "        #Edge case for variables with '=' characters in their values\n",
    "        if'\"' in var:\n",
    "            splitter2 = var.split('\"')\n",
    "            evidenceVariables[splitter2[0][:-1].strip()] = splitter2[1].strip()\n",
    "        else:\n",
    "            splitter2 = var.split(\"=\")\n",
    "            evidenceVariables[splitter2[0].strip()] = splitter2[1].strip()\n",
    "\n",
    "\n",
    "\n",
    "if ALGORITHM == \"gibbs\":\n",
    "    probDist = gibbsSampling(model,reportVariables,evidenceVariables, 2100000, 100000)\n",
    "elif ALGORITHM == \"ve\":\n",
    "    probDist = variableElim(reportVariables, evidenceVariables, model)\n",
    "    #print(probDist)\n",
    "    print(\"test\")\n",
    "else:\n",
    "    print(\"Unrecognized algorithm:\", ALGORITHM)\n",
    "\n",
    "createOutput(reportVariables, model, probDist)\n",
    "\n"
   ],
   "id": "491dad2a45902739",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'f_code'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     45\u001B[39m     probDist = gibbsSampling(model,reportVariables,evidenceVariables, \u001B[32m2100000\u001B[39m, \u001B[32m100000\u001B[39m)\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m ALGORITHM == \u001B[33m\"\u001B[39m\u001B[33mve\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     probDist = \u001B[43mvariableElim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreportVariables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevidenceVariables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m     \u001B[38;5;66;03m#print(probDist)\u001B[39;00m\n\u001B[32m     49\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mtest\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mvariableElim\u001B[39m\u001B[34m(query, observedValues, bayesianNetwork)\u001B[39m\n\u001B[32m      4\u001B[39m     variableElimination = makeFactors(variable, observedValues, bayesianNetwork) + variableElimination\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m variable \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m observedValues.keys() \u001B[38;5;129;01mand\u001B[39;00m variable \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m query:\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m         variableElimination = \u001B[43msumOut\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariableElimination\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m final = pointWise(variableElimination)\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m normalizeVEDistribution(final.values)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 139\u001B[39m, in \u001B[36msumOut\u001B[39m\u001B[34m(variable, variableElimination)\u001B[39m\n\u001B[32m    137\u001B[39m index = combine.variables.index(variable)\n\u001B[32m    138\u001B[39m oppose, \u001B[38;5;28mtuple\u001B[39m = variablesOppose(opposite, value, index)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43moppose\u001B[49m:\n\u001B[32m    140\u001B[39m     \u001B[38;5;28msum\u001B[39m += combine.values[opposite]\n\u001B[32m    141\u001B[39m     removed.append(opposite)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2025.2.0.1\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_frame.py:591\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    589\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m can_skip:\n\u001B[32m    590\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m plugin_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m main_debugger.has_plugin_line_breaks:\n\u001B[32m--> \u001B[39m\u001B[32m591\u001B[39m         can_skip = \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mplugin_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcan_not_skip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain_debugger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    593\u001B[39m     \u001B[38;5;66;03m# CMD_STEP_OVER = 108\u001B[39;00m\n\u001B[32m    594\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m can_skip \u001B[38;5;129;01mand\u001B[39;00m main_debugger.show_return_values \u001B[38;5;129;01mand\u001B[39;00m info.pydev_step_cmd == \u001B[32m108\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m frame.f_back \u001B[38;5;129;01mis\u001B[39;00m info.pydev_step_stop:\n\u001B[32m    595\u001B[39m         \u001B[38;5;66;03m# trace function for showing return values after step over\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2025.2.0.1\\plugins\\python-ce\\helpers\\jupyter_debug\\pydev_jupyter_plugin.py:92\u001B[39m, in \u001B[36mcan_not_skip\u001B[39m\u001B[34m(plugin, pydb, frame, info)\u001B[39m\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcan_not_skip\u001B[39m(plugin, pydb, frame, info):\n\u001B[32m     91\u001B[39m     step_cmd = info.pydev_step_cmd\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m step_cmd == \u001B[32m108\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[43m_is_equals\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_get_stop_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m     93\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m pydb.jupyter_breakpoints:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2025.2.0.1\\plugins\\python-ce\\helpers\\jupyter_debug\\pydev_jupyter_plugin.py:128\u001B[39m, in \u001B[36m_is_equals\u001B[39m\u001B[34m(frame, other_frame)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_is_equals\u001B[39m(frame, other_frame):\n\u001B[32m    125\u001B[39m     \u001B[38;5;66;03m# We can't compare frames directly, because Jupyter compiles ast nodes\u001B[39;00m\n\u001B[32m    126\u001B[39m     \u001B[38;5;66;03m# in cell separately. At the same time, the frame filename is unique and stays\u001B[39;00m\n\u001B[32m    127\u001B[39m     \u001B[38;5;66;03m# the same within a cell.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m frame.f_code.co_filename == \u001B[43mother_frame\u001B[49m\u001B[43m.\u001B[49m\u001B[43mf_code\u001B[49m.co_filename \\\n\u001B[32m    129\u001B[39m            \u001B[38;5;129;01mand\u001B[39;00m ((frame.f_code.co_name.startswith(\u001B[33m'\u001B[39m\u001B[33m<cell line:\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    130\u001B[39m                  \u001B[38;5;129;01mand\u001B[39;00m other_frame.f_code.co_name.startswith(\u001B[33m'\u001B[39m\u001B[33m<cell line:\u001B[39m\u001B[33m'\u001B[39m))\n\u001B[32m    131\u001B[39m                 \u001B[38;5;129;01mor\u001B[39;00m frame.f_code.co_name == other_frame.f_code.co_name)\n",
      "\u001B[31mAttributeError\u001B[39m: 'NoneType' object has no attribute 'f_code'"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
